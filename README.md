Absolutely, Mani â€” hereâ€™s a **refined and more polished version of your README**, with a tone that balances clarity and humility (since itâ€™s a hobby project):

---

# ðŸ“˜ Slide Extractor from Lecture Videos

A lightweight, Python-based tool for extracting clean slides from educational videos. It works by converting video frames into images, detecting slide transitions using OCR and image hashing, and exporting distinct slides into PDF documents.

This is a personal hobby project, and while it works well for my needs, it's still evolving â€” so expect occasional quirks or room for improvement. Feedback and suggestions are welcome!

---

## âœ¨ Features

* â±ï¸ Configurable frame extraction (e.g., every N seconds)
* ðŸ” OCR-based and hash-based filtering to keep only **distinct slides**
* ðŸŒ Multilingual support (can be edited in cofig file)
* ðŸ“„ Export selected slides as clean PDFs
* âš™ï¸ customizable via `config.py`
* ðŸ—ƒï¸ Basic batch processing for multiple videos

---

## ðŸ›  Installation

1. **Clone the repository:**

   ```bash
   git clone https://github.com/your_username/lecture2video.git
   cd lecture2video
   ```

2. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

3. **Install Tesseract OCR (if using default OCR engine):**

   * Windows: [Download here](https://github.com/tesseract-ocr/tesseract)
   * Alternative: Use `easyocr` by changing the `OCR_ENGINE` option in `config.py`

---

## â–¶ï¸ Usage

1. **Put your videos** inside the `videos/` folder (formats: `.mp4`, `.mkv`, `.avi`, etc.)

2. **Configure settings** in `config.py`. You'll find clear comments explaining each option.

3. **Run the pipeline:**

   ```bash
   python run_pipline.py
   ```

   This will:

   * Extract frames into `frames/`
   * Filter out repetitive frames and save key slides in `slides/`
   * (Optional) Export to PDF using a script or manually

4. **Get your final slides** in PDF format â€” either run the export manually or extend the pipeline to automate this step.

---

## âš™ï¸ Configuration Highlights (`config.py`)

* `FRAME_INTERVAL`: Time (in seconds) between extracted frames
* `OCR_ENGINE`: Choose `"tesseract"` or `"easyocr"`
* `TRANSLATION_MAP`: Map non-English video titles to safe folder names
* `CLEAN_TEXT_PATTERNS`: Regex patterns to clean noisy OCR output
* `CROP_MARGIN`, `HASH_SIM_THRESHOLD`, `OCR_SIM_THRESHOLD`: Finetune filtering sensitivity

---

## ðŸ“ Project Structure

```
lecture2video/
â”œâ”€â”€ videos/          # Input videos
â”œâ”€â”€ frames/          # Auto-generated raw frames
â”œâ”€â”€ slides/          # Filtered slides (clean and distinct)
â”œâ”€â”€ pdfs/            # Final exported PDFs
â”œâ”€â”€ scripts/         # Supporting scripts for processing
â”œâ”€â”€ run_pipline.py   # Main entry point
â”œâ”€â”€ config.py        # All the settings
â”œâ”€â”€ requirements.txt
```

---

## ðŸ’¡ Tips & Notes

* ðŸ“º Use clean, high-resolution videos for best OCR performance
* ðŸ§ª Play with `FRAME_INTERVAL`, OCR thresholds, and hash tolerance to tune results
* ðŸˆ· If working with non-English titles, use the `TRANSLATION_MAP` to avoid folder naming issues

---

## ðŸ“Œ Known Limitations

* Minor OCR inconsistencies (like confusing `O` with `0`, or `l` with `1`) may affect similarity detection â€” normalization is handled, but not perfect
* Frame comparison relies on both text and visual hash â€” tweaking thresholds might be necessary
* Some false positives/negatives may occur depending on slide layout or video compression

---

## ðŸ§ª Status

> ðŸš§ This is a personal, hobby-grade project and **not production-ready**. I'm sharing it in the hope that others might find it useful or build upon it. Use at your own discretion :)